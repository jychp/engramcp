name: 'Checks'

on:
  workflow_call:
  pull_request:

permissions:
  contents: read

jobs:
  python-lint:
    runs-on: ubuntu-latest
    timeout-minutes: 5
    steps:
      - uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6.0.2
        with:
          persist-credentials: false
      - uses: actions/setup-python@a309ff8b426b58ec0e2a45f0f869d46889d02405 # v6.2.0
        with:
          python-version-file: ".python-version"
      - name: Install uv
        uses: astral-sh/setup-uv@803947b9bd8e9f986429fa0c5a41c367cd732b41 # v7.2.1
        with:
          enable-cache: false
      - name: Install dependencies
        run: uv sync --frozen --dev
      - name: Run pre-commit
        run: uv run --frozen pre-commit run --all-files --show-diff-on-failure

  python-tests:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    steps:
      - uses: actions/checkout@de0fac2e4500dabe0009e67214ff5f5447ce83dd # v6.0.2
        with:
          persist-credentials: false
      - uses: actions/setup-python@a309ff8b426b58ec0e2a45f0f869d46889d02405 # v6.2.0
        with:
          python-version-file: ".python-version"
      - name: Install uv
        uses: astral-sh/setup-uv@803947b9bd8e9f986429fa0c5a41c367cd732b41 # v7.2.1
        with:
          enable-cache: true
          cache-dependency-glob: "uv.lock"
      - name: Install the project
        run: uv sync --frozen --all-extras --dev
      - name: Unit + integration tests
        run: uv run --frozen pytest -vvv --cov-report term-missing --cov=engramcp -m "unit or integration" tests/
      - name: Scenario evals (non real_llm)
        run: make test-scenarios
      - name: Calibrate eval thresholds
        run: uv run --frozen python scripts/calibrate_eval_thresholds.py --metrics reports/scenario-metrics.jsonl --output reports/eval-calibration.json
      - name: Upload scenario JUnit report
        if: always()
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: pytest-scenarios-report
          path: reports/pytest-scenarios.xml
      - name: Upload scenario metrics + calibration artifacts
        if: always()
        uses: actions/upload-artifact@b7c566a772e6b6bfb58ed0dc250532a479d7789f # v6.0.0
        with:
          name: scenario-calibration-report
          path: |
            reports/scenario-metrics.jsonl
            reports/eval-calibration.json
